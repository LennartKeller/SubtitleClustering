{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.base import clone as clone_estimator\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/movies_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning DBScan\n",
    "\n",
    "We want to tune the hyperparamter of DBScan.\n",
    "Since choosing a clustering perfomance metric is not a trivial task our first objective is to get balanced sized clusters.\n",
    "To achieve this we consider the std-deviation of the number of instances per cluster. Since DBScan marks points which could not be assigned to one cluster as noise we also want to reduce the number of points marked as noise. Also we want to get more than one Cluster (ignoring the noise cluster)\n",
    "\n",
    "$perf_{dbscan}(labels) = (\\frac{N_{noise}}{N})*std(labels) * log(N_{cluster})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_ratio(labels):\n",
    "    noise = labels[labels == -1]\n",
    "    return noise.shape[0] / labels.shape[0]\n",
    "\n",
    "def dbscan_objective(labels):\n",
    "    noise_ratio = get_noise_ratio(labels) +  0.0001\n",
    "    # get clusters\n",
    "    cluster = labels[labels != -1]\n",
    "    n_cluster = len(cluster)\n",
    "    # get cluster distribution\n",
    "    bins = np.array(list(Counter(cluster).values()))\n",
    "    cluster_size_std = bins.std() if len(bins) > 2 else 0.0001\n",
    "    return (1- noise_ratio) * n_cluster * np.abs(np.log(cluster_size_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.17753448333968"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "labels = np.array([random.randint(-1, 5) for _ in range(100)])\n",
    "#labels = np.array([-1 for _ in range(100)])\n",
    "dbscan_objective(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBScan-Parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ParameterGrid({\n",
    "    'metric': ['cosine', 'euclidean', 'manhattan'],\n",
    "    'eps': np.linspace(0, 5, 10)[1:],\n",
    "    'min_samples': list(range(1,20)) \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(clu: DBSCAN, params: ParameterGrid, X: np.ndarray, verbose=True) -> pd.DataFrame:\n",
    "    results = []\n",
    "    params = tqdm(params) if verbose else params\n",
    "    for param_comb in params:\n",
    "        labels = clone_estimator(clu).fit_predict(X)\n",
    "        score = dbscan_objective(labels)\n",
    "        noise_ratio = get_noise_ratio(labels)\n",
    "        param_comb['score'] = score\n",
    "        param_comb['noise_ration'] = noise_ratio\n",
    "        params.set_description(f'{score}|{noise_ratio}')\n",
    "        results.append(param_comb)\n",
    "    return pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Run\n",
    "We use only Tfidf-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.5, max_features=10000, stop_words=get_stop_words('de'))\n",
    "Xtfidf = tfidf.fit_transform(df.text).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2134bce9cfa94ddb8e0a04ad47761289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=513.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tifidf_simple = run(clu=DBSCAN(n_jobs=12), params=params, X=Xtfidf, verbose=True)\n",
    "tfidf_simple.to_csv('../Results/DBScan_Tfidf_Simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
